# Copyright 2024 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Records a dataset. Actions for the robot are generated by teleoperation or manual demonstration
(e.g. moving the robot directly in gravity compensation mode).
"""

import logging
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from pprint import pformat

from lerobot.cameras import (  # noqa: F401
    CameraConfig,  # noqa: F401
)
from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig  # noqa: F401
from lerobot.cameras.realsense.configuration_realsense import (
    RealSenseCameraConfig,
)  # noqa: F401
from lerobot.configs import parser
from lerobot.datasets.image_writer import safe_stop_image_writer
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.datasets.pipeline_features import (
    aggregate_pipeline_dataset_features,
    create_initial_features,
)
from lerobot.datasets.utils import build_dataset_frame, combine_feature_dicts
from lerobot.datasets.video_utils import VideoEncodingManager
from lerobot.processor import (
    RobotAction,
    RobotObservation,
    RobotProcessorPipeline,
    make_default_processors,
)
from lerobot.robots import (  # noqa: F401
    Robot,
    RobotConfig,
    bi_arx5,
    flexiv_rizon4,  # noqa: F401
    make_robot_from_config,
    xense_flare,  # noqa: F401
)
from lerobot.teleoperators import (  # noqa: F401
    Teleoperator,
    TeleoperatorConfig,
    make_teleoperator_from_config,
)
# Import mock_teleop to register its config with draccus ChoiceRegistry
try:
    from lerobot.teleoperators.mock_teleop import MockTeleopConfig  # noqa: F401
except ImportError:
    # If tests are not available, mock_teleop won't be available
    pass
from lerobot.utils.constants import ACTION, OBS_STR
from lerobot.utils.control_utils import (
    init_keyboard_listener,
    is_headless,
    sanity_check_dataset_robot_compatibility,
)
from lerobot.utils.import_utils import register_third_party_devices
from lerobot.utils.robot_utils import busy_wait
from lerobot.utils.utils import (
    init_logging,
    log_say,
)
from lerobot.utils.visualization_utils import init_rerun, log_rerun_data


@dataclass
class DatasetRecordConfig:
    # Dataset identifier. By convention it should match '{hf_username}/{dataset_name}' (e.g. `lerobot/test`).
    repo_id: str
    # A short but accurate description of the task performed during the recording (e.g. "Pick the Lego block and drop it in the box on the right.")
    single_task: str
    # Root directory where the dataset will be stored (e.g. 'dataset/path').
    root: str | Path | None = None
    # Limit the frames per second.
    fps: int = 30
    # Number of seconds for data recording for each episode.
    episode_time_s: int | float = 60
    # Number of seconds for resetting the environment after each episode.
    reset_time_s: int | float = 60
    # Number of episodes to record.
    num_episodes: int = 50
    # Encode frames in the dataset into video
    video: bool = True
    # Upload dataset to Hugging Face hub.
    push_to_hub: bool = True
    # Upload on private repository on the Hugging Face hub.
    private: bool = False
    # Add tags to your dataset on the hub.
    tags: list[str] | None = None
    # Number of subprocesses handling the saving of frames as PNG. Set to 0 to use threads only;
    # set to ≥1 to use subprocesses, each using threads to write images. The best number of processes
    # and threads depends on your system. We recommend 4 threads per camera with 0 processes.
    # If fps is unstable, adjust the thread count. If still unstable, try using 1 or more subprocesses.
    num_image_writer_processes: int = 0
    # Number of threads writing the frames as png images on disk, per camera.
    # Too many threads might cause unstable teleoperation fps due to main thread being blocked.
    # Not enough threads might cause low camera fps.
    num_image_writer_threads_per_camera: int = 4
    # Number of episodes to record before batch encoding videos
    # Set to 1 for immediate encoding (default behavior), or higher for batched encoding
    video_encoding_batch_size: int = 1
    def __post_init__(self):
        if self.single_task is None:
            raise ValueError("You need to provide a task as argument in `single_task`.")


@dataclass
class RecordConfig:
    robot: RobotConfig
    dataset: DatasetRecordConfig
    # Whether to control the robot with a teleoperator
    teleop: TeleoperatorConfig | None = None
    # Display all cameras on screen
    display_data: bool = False
    # Use vocal synthesis to read events.
    play_sounds: bool = True
    # Resume recording on an existing dataset.
    resume: bool = False

    def __post_init__(self):
        # XenseFlare acts as both robot and teleoperator (provides actions via get_action()).
        # BiARX5 can be recorded in manual mode without a teleoperator.
        if self.teleop is None and self.robot.type not in ("xense_flare", "bi_arx5"):
            raise ValueError("Choose a teleoperator to control the robot.")


""" --------------- record_loop() data flow --------------------------
       [ Robot ]
           V
     [ robot.get_observation() ] ---> raw_obs
           V
     [ robot_observation_processor ] ---> processed_obs
           V
     [ teleop.get_action() ] ---> raw_action
           V
     [ teleop_action_processor ] ---> processed_action
           V
     [ robot_action_processor ] ---> robot_action_to_send
           V
     [ robot.send_action() ] -- (Robot Executes)
           V
     ( Save to Dataset )
           V
     ( Rerun Log / Loop Wait )
"""


def extract_joint_positions(obs):
    """提取关节位置，排除摄像头数据"""
    joint_positions = {}
    for key, value in obs.items():
        if (
            key.endswith(".pos")
            and not key.startswith("head")
            and not key.startswith("left_wrist")
            and not key.startswith("right_wrist")
        ):
            joint_positions[key] = value
    return joint_positions


def apply_velocity_limits(
    current_action: dict, prev_action: dict, dt: float, robot=None
) -> dict:
    """Apply velocity limits to action to ensure consistency with inference-time clipping.

    This ensures that recorded actions are physically executable during replay or downstream use.

    Args:
        current_action: Current action dictionary with joint positions
        prev_action: Previous action dictionary with joint positions
        dt: Time step between actions (typically 1/fps)
        robot: Robot instance to get velocity limits from robot_configs

    Returns:
        Velocity-limited action dictionary
    """
    if prev_action is None:
        return current_action

    # Get velocity limits from robot config to ensure consistency with C++ settings
    if robot is not None and hasattr(robot, "robot_configs"):
        # Read from robot config (same as C++ controller uses)
        left_config = robot.robot_configs["left_config"]
        joint_vel_limits = (
            left_config.joint_vel_max.tolist()
        )  # Convert numpy array to list
        gripper_vel_limit = left_config.gripper_vel_max
    else:
        # Fallback to hardcoded values if robot config not available
        # From config.h: [20.0, 20.0, 20.5, 20.5, 20.0, 20.0] rad/s, gripper: 0.3 m/s
        joint_vel_limits = [20.0, 20.0, 20.5, 20.5, 20.0, 20.0]  # rad/s
        gripper_vel_limit = 0.3  # m/s

    limited_action = current_action.copy()
    clip_count = 0

    # Apply joint velocity limits
    for i in range(6):
        left_key = f"left_joint_{i+1}.pos"
        right_key = f"right_joint_{i+1}.pos"

        for key in [left_key, right_key]:
            if key in current_action and key in prev_action:
                current_pos = current_action[key]
                prev_pos = prev_action[key]
                delta_pos = current_pos - prev_pos
                max_delta = joint_vel_limits[i] * dt

                if abs(delta_pos) > max_delta:
                    # Clip to maximum allowed change
                    sign = 1 if delta_pos > 0 else -1
                    limited_action[key] = prev_pos + sign * max_delta
                    clip_count += 1
                    logging.debug(
                        f"Clipped {key}: {delta_pos:.3f} -> {sign * max_delta:.3f} rad"
                    )

    # Apply gripper velocity limits
    for gripper_key in ["left_gripper.pos", "right_gripper.pos"]:
        if gripper_key in current_action and gripper_key in prev_action:
            current_pos = current_action[gripper_key]
            prev_pos = prev_action[gripper_key]
            delta_pos = current_pos - prev_pos
            max_delta = gripper_vel_limit * dt

            if abs(delta_pos) > max_delta:
                # Clip to maximum allowed change
                sign = 1 if delta_pos > 0 else -1
                limited_action[gripper_key] = prev_pos + sign * max_delta
                clip_count += 1
                logging.debug(
                    f"Clipped {gripper_key}: {delta_pos:.3f} -> {sign * max_delta:.3f} m"
                )

    if clip_count > 0:
        logging.debug(f"Applied velocity limits: {clip_count} joints clipped")

    return limited_action


@safe_stop_image_writer
def bi_arx5_record_loop(
    robot: Robot,
    events: dict,
    fps: int,
    teleop_action_processor: RobotProcessorPipeline[
        tuple[RobotAction, RobotObservation], RobotAction
    ],  # runs after teleop
    robot_action_processor: RobotProcessorPipeline[
        tuple[RobotAction, RobotObservation], RobotAction
    ],  # runs before robot
    robot_observation_processor: RobotProcessorPipeline[
        RobotObservation, RobotObservation
    ],  # runs after robot
    dataset: LeRobotDataset | None = None,
    teleop: Teleoperator | list[Teleoperator] | None = None,
    control_time_s: int | None = None,
    single_task: str | None = None,
    display_data: bool = False,
):
    """
    Specialized record loop for BiARX5 robot supporting teleop and manual demonstration modes.

    Teleop mode:
    - Uses teleoperator actions to control the robot
    - Saves current observation with actually sent action

    Manual demonstration mode (no teleop) with action shifting:
    - Frame 0: Only records observation, no dataset entry created
    - Frame 1+: Creates dataset entry using prev_observation and current joint positions as action
    - Last frame: Gets discarded (no dataset entry)

    This is optimized for dual-arm robots where the human manually moves the robot arms
    while in gravity compensation mode, and the system records the joint positions as demonstrations.

    Action shifting in manual mode ensures that action[t] corresponds to the state that will be reached at time t+1.
    """

    if dataset is not None and dataset.fps != fps:
        raise ValueError(
            f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps})."
        )

    if isinstance(teleop, list):
        raise ValueError("Multi-teleop mode is not supported in this version.")

    use_teleop = isinstance(teleop, Teleoperator)

    timestamp = 0
    start_episode_t = time.perf_counter()

    # Variables for action shifting (only used in manual demonstration mode)
    prev_observation = None
    prev_observation_frame = None

    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        if events["exit_early"]:
            events["exit_early"] = False
            break

        # Handle rerecord_episode event (same as standard record_loop)
        if events["rerecord_episode"]:
            # Don't reset the event here - let the main record() function handle it
            logging.info("Re-record episode requested, exiting record loop early")
            break

        # Handle go_home event for BiARX5 robot when recording (non-blocking)
        if events["go_start"] and not use_teleop:
            events["go_start"] = False
            logging.info(
                "Starting smooth_go_start in background while recording continues..."
            )

            # Execute smooth_go_start in a separate thread to avoid blocking
            import threading

            def go_start_thread():
                try:
                    robot.smooth_go_start(duration=3.0)
                    logging.info(
                        "✅ smooth_go_start completed successfully in 2 seconds"
                    )
                except Exception as e:
                    logging.error(f"Error during smooth_go_start: {e}")

            thread = threading.Thread(target=go_start_thread, daemon=True)
            thread.start()

        # Get robot observation
        current_observation = robot.get_observation()
        current_observation_processed = robot_observation_processor(current_observation)
        current_observation_frame = None

        if dataset is not None:
            current_observation_frame = build_dataset_frame(
                dataset.features, current_observation_processed, prefix=OBS_STR
            )

        if use_teleop:
            act = teleop.get_action()
            act_processed = teleop_action_processor((act, current_observation))
            robot_action_to_send = robot_action_processor((act_processed, current_observation))
            _sent_action = robot.send_action(robot_action_to_send)

            if dataset is not None:
                action_frame = build_dataset_frame(
                    dataset.features, act_processed, prefix=ACTION
                )
                frame = {**current_observation_frame, **action_frame, "task": single_task}
                dataset.add_frame(frame)
        else:
            current_action = extract_joint_positions(current_observation)
            # Action shifting logic: from second frame onwards, create dataset entries
            if prev_observation is not None and dataset is not None:
                # Manual demonstration mode with action shifting
                # Use current frame's joint positions as previous frame's action

                # Apply velocity limits to ensure consistency with inference-time clipping
                prev_action = extract_joint_positions(prev_observation)
                limited_action = apply_velocity_limits(
                    current_action, prev_action, 1.0 / fps, robot
                )
                action_frame = build_dataset_frame(
                    dataset.features, limited_action, prefix=ACTION
                )
                frame = {**prev_observation_frame, **action_frame, "task": single_task}
                dataset.add_frame(frame)

        if display_data:
            display_action = (
                act_processed if use_teleop else extract_joint_positions(current_observation_processed)
            )
            log_rerun_data(observation=current_observation_processed, action=display_action)

        # Update for next iteration
        prev_observation = current_observation
        prev_observation_frame = current_observation_frame

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t


@safe_stop_image_writer
def xense_flare_record_loop(
    robot: Robot,
    events: dict,
    fps: int,
    dataset: LeRobotDataset | None = None,
    control_time_s: int | None = None,
    single_task: str | None = None,
    display_data: bool = False,
):
    """
    Record loop for XenseFlare data collection gripper.

    XenseFlare is special because it acts as both:
    - A robot (provides observation: camera, tactile, gripper position)
    - A teleoperator (provides action: Vive Tracker pose + gripper position)

    The action comes from robot.get_action() instead of a separate teleoperator.
    """
    if dataset is not None and dataset.fps != fps:
        raise ValueError(
            f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps})."
        )

    timestamp = 0
    start_episode_t = time.perf_counter()

    # Variables for action shifting (only used in manual demonstration mode)
    prev_observation = None
    prev_observation_frame = None

    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        if events["exit_early"]:
            events["exit_early"] = False
            break

        if events["rerecord_episode"]:
            logging.info("Re-record episode requested, exiting record loop early")
            break

        # Get robot observation (camera, tactile, gripper position)
        current_observation = robot.get_observation()
        current_observation_frame = None

        if dataset is not None:
            current_observation_frame = build_dataset_frame(
                dataset.features, current_observation, prefix=OBS_STR
            )

        current_action = robot.get_action()

        if prev_observation is not None and dataset is not None:
            # Manual demonstration mode with action shifting
            # Use current frame's action as previous frame's action
            current_action_frame = build_dataset_frame(dataset.features, current_action, prefix=ACTION)

            frame = {**prev_observation_frame, **current_action_frame, "task": single_task}
            dataset.add_frame(frame)

        if display_data:
            log_rerun_data(observation=current_observation, action=current_action)

        # Update for next iteration
        prev_observation = current_observation
        prev_observation_frame = current_observation_frame

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t


@safe_stop_image_writer
def record_loop(
    robot: Robot,
    events: dict,
    fps: int,
    teleop_action_processor: RobotProcessorPipeline[
        tuple[RobotAction, RobotObservation], RobotAction
    ],  # runs after teleop
    robot_action_processor: RobotProcessorPipeline[
        tuple[RobotAction, RobotObservation], RobotAction
    ],  # runs before robot
    robot_observation_processor: RobotProcessorPipeline[
        RobotObservation, RobotObservation
    ],  # runs after robot
    dataset: LeRobotDataset | None = None,
    teleop: Teleoperator | list[Teleoperator] | None = None,
    control_time_s: int | None = None,
    single_task: str | None = None,
    display_data: bool = False,
):
    if dataset is not None and dataset.fps != fps:
        raise ValueError(
            f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps})."
        )

    if isinstance(teleop, list):
        raise ValueError("Multi-teleop mode is not supported in this version.")
    if not isinstance(teleop, Teleoperator):
        raise ValueError("A teleoperator is required to record actions for this robot.")

    timestamp = 0
    start_episode_t = time.perf_counter()
    while timestamp < control_time_s:
        start_loop_t = time.perf_counter()

        if events["exit_early"]:
            events["exit_early"] = False
            break

        # Get robot observation
        obs = robot.get_observation()

        # Applies a pipeline to the raw robot observation, default is IdentityProcessor
        obs_processed = robot_observation_processor(obs)

        if dataset is not None:
            observation_frame = build_dataset_frame(
                dataset.features, obs_processed, prefix=OBS_STR
            )

        act = teleop.get_action()

        # Applies a pipeline to the raw teleop action, default is IdentityProcessor
        act_processed_teleop = teleop_action_processor((act, obs))

        # Applies a pipeline to the action, default is IdentityProcessor
        action_values = act_processed_teleop
        robot_action_to_send = robot_action_processor((act_processed_teleop, obs))

        # Send action to robot
        # Action can eventually be clipped using `max_relative_target`,
        # so action actually sent is saved in the dataset. action = postprocessor.process(action)
        # TODO(steven, pepijn, adil): we should use a pipeline step to clip the action, so the sent action is the action that we input to the robot.
        _sent_action = robot.send_action(robot_action_to_send)

        # Write to dataset
        if dataset is not None:
            action_frame = build_dataset_frame(
                dataset.features, action_values, prefix=ACTION
            )
            frame = {**observation_frame, **action_frame, "task": single_task}
            dataset.add_frame(frame)

        if display_data:
            log_rerun_data(observation=obs_processed, action=action_values)

        dt_s = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_s)

        timestamp = time.perf_counter() - start_episode_t


@parser.wrap()
def record(cfg: RecordConfig) -> LeRobotDataset:
    init_logging()
    logging.info(pformat(asdict(cfg)))
    if cfg.display_data:
        init_rerun(session_name="recording")

    robot = make_robot_from_config(cfg.robot)
    teleop = (
        make_teleoperator_from_config(cfg.teleop) if cfg.teleop is not None else None
    )

    teleop_action_processor, robot_action_processor, robot_observation_processor = (
        make_default_processors()
    )

    dataset_features = combine_feature_dicts(
        aggregate_pipeline_dataset_features(
            pipeline=teleop_action_processor,
            initial_features=create_initial_features(
                action=robot.action_features
            ),  # TODO(steven, pepijn): in future this should come from teleop metadata
            use_videos=cfg.dataset.video,
        ),
        aggregate_pipeline_dataset_features(
            pipeline=robot_observation_processor,
            initial_features=create_initial_features(
                observation=robot.observation_features
            ),
            use_videos=cfg.dataset.video,
        ),
    )

    if cfg.resume:
        dataset = LeRobotDataset(
            cfg.dataset.repo_id,
            root=cfg.dataset.root,
            batch_encoding_size=cfg.dataset.video_encoding_batch_size,
        )

        if hasattr(robot, "cameras") and len(robot.cameras) > 0:
            dataset.start_image_writer(
                num_processes=cfg.dataset.num_image_writer_processes,
                num_threads=cfg.dataset.num_image_writer_threads_per_camera
                * len(robot.cameras),
            )
        sanity_check_dataset_robot_compatibility(
            dataset, robot, cfg.dataset.fps, dataset_features
        )
    else:
        # Create empty dataset or load existing saved episodes
        dataset = LeRobotDataset.create(
            cfg.dataset.repo_id,
            cfg.dataset.fps,
            root=cfg.dataset.root,
            robot_type=robot.name,
            features=dataset_features,
            use_videos=cfg.dataset.video,
            image_writer_processes=cfg.dataset.num_image_writer_processes,
            image_writer_threads=cfg.dataset.num_image_writer_threads_per_camera
            * len(robot.cameras),
            batch_encoding_size=cfg.dataset.video_encoding_batch_size,
        )

    robot.connect()
    if teleop is not None:
        teleop.connect()

    listener, events = init_keyboard_listener()

    try:
        with VideoEncodingManager(dataset):
            recorded_episodes = 0
            while (
                recorded_episodes < cfg.dataset.num_episodes
                and not events["stop_recording"]
            ):
                log_say(f"Recording episode {dataset.num_episodes}", cfg.play_sounds)

                # Use specialized record loop for XenseFlare (data collection gripper)
                if cfg.robot.type == "xense_flare":
                    xense_flare_record_loop(
                        robot=robot,
                        events=events,
                        fps=cfg.dataset.fps,
                        dataset=dataset,
                        control_time_s=cfg.dataset.episode_time_s,
                        single_task=cfg.dataset.single_task,
                        display_data=cfg.display_data,
                    )
                # Use specialized record loop for BiARX5 robot
                elif cfg.robot.type == "bi_arx5":
                    bi_arx5_record_loop(
                        robot=robot,
                        events=events,
                        fps=cfg.dataset.fps,
                        teleop_action_processor=teleop_action_processor,
                        robot_action_processor=robot_action_processor,
                        robot_observation_processor=robot_observation_processor,
                        teleop=teleop,
                        dataset=dataset,
                        control_time_s=cfg.dataset.episode_time_s,
                        single_task=cfg.dataset.single_task,
                        display_data=cfg.display_data,
                    )
                else:
                    record_loop(
                        robot=robot,
                        events=events,
                        fps=cfg.dataset.fps,
                        teleop_action_processor=teleop_action_processor,
                        robot_action_processor=robot_action_processor,
                        robot_observation_processor=robot_observation_processor,
                        teleop=teleop,
                        dataset=dataset,
                        control_time_s=cfg.dataset.episode_time_s,
                        single_task=cfg.dataset.single_task,
                        display_data=cfg.display_data,
                    )
                # Execute a few seconds without recording to give time to manually reset the environment
                # Skip reset for the last episode to be recorded
                if not events["stop_recording"] and (
                    (recorded_episodes < cfg.dataset.num_episodes - 1)
                    or events["rerecord_episode"]
                ):
                    log_say("Reset the environment", cfg.play_sounds)
                    if cfg.robot.type == "xense_flare":
                        xense_flare_record_loop(
                            robot=robot,
                            events=events,
                            fps=cfg.dataset.fps,
                            control_time_s=cfg.dataset.reset_time_s,
                            single_task=cfg.dataset.single_task,
                            display_data=cfg.display_data,
                        )
                    elif cfg.robot.type == "bi_arx5":
                        bi_arx5_record_loop(
                            robot=robot,
                            events=events,
                            fps=cfg.dataset.fps,
                            teleop_action_processor=teleop_action_processor,
                            robot_action_processor=robot_action_processor,
                            robot_observation_processor=robot_observation_processor,
                            teleop=teleop,
                            control_time_s=cfg.dataset.reset_time_s,
                            single_task=cfg.dataset.single_task,
                            display_data=cfg.display_data,
                        )
                    else:
                        record_loop(
                            robot=robot,
                            events=events,
                            fps=cfg.dataset.fps,
                            teleop_action_processor=teleop_action_processor,
                            robot_action_processor=robot_action_processor,
                            robot_observation_processor=robot_observation_processor,
                            teleop=teleop,
                            control_time_s=cfg.dataset.reset_time_s,
                            single_task=cfg.dataset.single_task,
                            display_data=cfg.display_data,
                        )

                if events["rerecord_episode"]:
                    log_say("Re-record episode", cfg.play_sounds)
                    events["rerecord_episode"] = False
                    events["exit_early"] = False
                    dataset.clear_episode_buffer()
                    continue

                dataset.save_episode()
                recorded_episodes += 1

        log_say("Stop recording", cfg.play_sounds, blocking=True)
    except KeyboardInterrupt:
        logging.info("\nKeyboardInterrupt received. Stopping recording...")
    except Exception as e:
        logging.error(f"Error during recording: {e}")
    finally:
        # Always disconnect robot and teleop safely
        try:
            if robot.is_connected:
                logging.info("Disconnecting robot...")
                robot.disconnect()
                logging.info("✅ Robot disconnected safely")
        except Exception as e:
            logging.error(f"Error during robot disconnect: {e}")

        try:
            if (
                teleop is not None
                and hasattr(teleop, "is_connected")
                and teleop.is_connected
            ):
                logging.info("Disconnecting teleop...")
                teleop.disconnect()
                logging.info("✅ Teleop disconnected safely")
        except Exception as e:
            logging.error(f"Error during teleop disconnect: {e}")

        try:
            if not is_headless() and listener is not None:
                listener.stop()
        except Exception as e:
            logging.error(f"Error stopping listener: {e}")

        try:
            if cfg.dataset.push_to_hub:
                dataset.push_to_hub(
                    tags=cfg.dataset.tags,
                    private=cfg.dataset.private,
                    upload_large_folder=True,
                )
        except Exception as e:
            logging.error(f"Error pushing to hub: {e}")

    log_say("Exiting", cfg.play_sounds)
    return dataset


def main():
    register_third_party_devices()
    record()


if __name__ == "__main__":
    main()
